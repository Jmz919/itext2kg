!pip install spacy langchain_ollama langchain


%load_ext autoreload
%autoreload 2

import sys

import spacy
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain.document_loaders import PyPDFLoader, TextLoader


sys.path.append("..")
from itext2kg.documents_distiller import DocumentsDisiller, CV, Article
from itext2kg.irelations_extraction import iRelationsExtractor








spacy.prefer_gpu()
nlp = spacy.load("en_core_web_trf")


llm = ChatOllama(
    model="gemma2",
    temperature=0,
    max_retries=5,
    max_tokens=None,
)

embeddings = OllamaEmbeddings(
    model="gemma2",
)





from langchain.document_loaders import PyPDFLoader, TextLoader

# loader = TextLoader("../datasets/cvs/Emily_Davis.txt")
loader = TextLoader("../datasets/scientific_articles/bertology.txt")
pages = loader.load()
pages = [page.page_content.replace("{", "").replace("}", "") for page in pages]
pages

loader = PyPDFLoader(f"../datasets/scientific_articles/bertology.pdf")
pages = loader.load()
pages = [page.page_content.replace("{", "").replace("}", "") for page in pages]

pages


global_ent = []
entities = []
for page in pages:
    doc = nlp(page)
    # page_entities = []
    entity_types = ["PERSON", "GPE", "LOC", "ORG"]
    for ent in doc.ents:
        if ent.label_ in entity_types and ent.text not in entities:
            # page_entities.append(ent.text)
            entities.append(ent.text)
            
            ent_json = {
                'label': ent.label_,
                'name': ent.text,
                'properties': {"embedding": embeddings.embed_query(ent.text)}
            }
            global_ent.append(ent_json)





from itext2kg.documents_distiller import DocumentsDisiller, CV

document_distiller = DocumentsDisiller(llm_model = llm)


# IE_query = '''
# # DIRECTIVES : 
# - Act like an experienced information extractor. 
# - You have a chunk of a CV.
# - If you do not find the right information, keep its place empty.
# '''

IE_query = '''
# DIRECTIVES : 
- Act like an experienced information extractor. 
- You have a chunk of a scientific paper.
- If you do not find the right information, keep its place empty.
'''
# we have replaced the curly braces with square brackets to avoid the error in the query
distilled_cv = document_distiller.distill(documents=pages, IE_query=IE_query, output_data_structure=Article)


semantic_blocks = [f"{key} - {value}".replace("{", "[").replace("}", "]") for key, value in distilled_cv.items() if value !=[] and value != ""  and value != None]
semantic_blocks


relationships = []

for semantic_block in semantic_blocks:
    irelations_extractor = iRelationsExtractor(llm_model=llm, 
                                               embeddings_model=embeddings,
                                               sleep_time=5)

    rels = irelations_extractor.extract_relations(context=semantic_block, entities=entities)
    relationships.append(rels)

relationships


# prev_rels = relationships
count = 0
for rels in relationships:
    count += len(rels)

count





global_rel = []
for rels in relationships:
    for rel in rels:
        rel["name"] = rel["name"].replace(" ", "_")
        global_rel.append(rel)

global_rel


len(global_ent)





from itext2kg.graph_integration import GraphIntegrator

URI = "bolt://localhost:7687"
USERNAME = "neo4j"
PASSWORD = "secretgraph"

new_graph = {}
new_graph["nodes"] = global_ent
new_graph["relationships"] = global_rel
GraphIntegrator(uri=URI, username=USERNAME, password=PASSWORD).visualize_graph(json_graph=new_graph)
